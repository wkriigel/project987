

---


1. **Functionality**: the app runs end-to-end, produces correct CSVs and the styled table, and supports Cars.com, TrueCar, and Carvana.

2. **Efficiency of iteration**: the codebase is lean, avoids redundant layers, minimizes dependencies, and has a process that supports fast iteration.

---

## **1\. Functional Scope**

* **Collector (AutoTempest-first)**

  * Always use **headful Playwright**.

  * Collect VDP URLs from AutoTempest search results.

  * Capture multiple sources: **cars.com**, **truecar.com**, **carvana.com**.

  * Each collected row: `{ "source": "<host>", "listing_url": "<url>" }`.

* **Scraper (Universal VDP)**

  * One scraper engine (`universal_vdp`) processes all VDPs.

  * Profiles provide **site hints** (selectors, wait conditions, known quirks).

  * Shared regex/core patterns handle: `price`, `mileage`, `year`, `vin`, `transmission`, `colors`, `location`.

Output contract is **identical** across sites:

 source, listing\_url, vin, year, model, trim, transmission\_raw,  
mileage, price\_usd, exterior\_color, interior\_color, raw\_options, location

*   
* **Transform**

  * Normalization stays the same.

  * Transmission normalization includes **Tiptronic → Automatic**.

* **Pipeline**

  * `collect` → `scrape` → `transform` → `dedupe` → `fairvalue` → `baseline` → `rank`.

  * No change to scoring, fair value, baseline, or ranking.

  * Each step still writes CSVs and passes the output forward.

* **View**


  * Source column should clearly reflect the host (cars.com, truecar.com, carvana.com).

---

## **2\. Repo & Structure**

x987/  
  \_\_init\_\_.py  
  \_\_main\_\_.py  
  cli.py  
  settings.py  
  doctor.py  
  schema.py  
  utils/  
    io.py  
    log.py  
    text.py  
  collectors/  
    autotempest.py  
  scrapers/  
    universal\_vdp.py  
    profiles/  
      cars\_com.py  
      truecar\_com.py  
      carvana\_com.py  
  pipeline/  
    collect.py  
    scrape.py  
    transform.py  
    dedupe.py  
    fairvalue.py  
    baseline.py  
    rank.py  
  view/  
    report.py  
options\_v2.py   ← canonical options, imported by transform


* **Profiles**: minimal, per-site selectors only. Core parsing lives in `universal_vdp.py`.

---

## **3\. Dependencies**

* **Keep only**:

  * `playwright`

  * `rich`

  * `tomli` (if \<3.11) / `tomllib` (\>=3.11 stdlib)

* **Remove**: `pydantic`, `rapidfuzz`, `dateutil`, unnecessary test/lint deps.

* **Doctor**: check only these packages \+ Playwright browser installed.

---

## **4\. Testing & Verification**

* **Trimmed tests**:

  * **Smoke test**: AutoTempest with mixed sources → pipeline → table. Confirms all core fields parse.

  * **Parser micro-test**: feed canned HTML snippets to `universal_vdp.parse()` → assert extraction of price, miles, VIN, transmission.

* **Drop**: extensive per-site unit tests, heavy lint gates.

* **Manual check**: run with Cars.com-only input, diff output CSV with v2 baseline → ensure no regressions in pricing/scoring/view.

---

## **5\. Process Notes**

* **Iteration efficiency is equal to correctness**. Each step must be rebuildable and testable in isolation:

  * **Collector** can run standalone and dump URLs.

  * **Scraper** can run on a file of URLs and dump raw rows.

  * **Transform** and onward can run on a CSV input.

* **Headful only** ensures predictable results and avoids wasted cycles debugging headless quirks.

* **Universal scraper** avoids proliferation of fragile site-specific modules — only profiles differ.

* **Lean repo** makes CI/local runs fast and cuts debugging surface.

* **Partial failure tolerance**: if a scrape fails, produce a row with `error` field, do not crash pipeline.

---

---

